{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
    
        
      
    
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc6rDVZgnLDK"
      },
      "source": [
        "# LLM Deployment for Shoplite (Colab-ready)\n",
        "\n",
        "This notebook is self-contained. It embeds the Shoplite knowledge base, builds a FAISS index with `sentence-transformers`, loads an open-source LLM (Llama 3.1 8B by default), exposes a Flask API (`/chat`, `/ping`, `/health`) and uses `pyngrok` to create a public tunnel.\n",
        "\n",
        "**IMPORTANT**: Instructors must supply their ngrok authtoken via an `input()` prompt at runtime. Do NOT hardcode tokens. If the model cannot be loaded in Colab due to size or access restrictions, follow the troubleshooting notes in the last cell to switch to a smaller model or use quantized loading."
      ],
      "id": "lc6rDVZgnLDK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGZOzzgnLDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4bab8b7-7a72-417d-fdc2-2edfd0da2174"
      },
      "source": [
        "# Cell 1: Install dependencies\n",
        "# Run this cell in Colab (ensure GPU runtime selected: Runtime -> Change runtime type -> GPU)\n",
        "!pip install --quiet --upgrade pip\n",
        "!pip install --quiet transformers accelerate bitsandbytes safetensors sentence-transformers faiss-cpu flask pyngrok uvicorn gunicorn -U\n",
        "# bitsandbytes is used for 8-bit loading/quantization; accelerate helps with device mapping\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.8/1.8 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "id": "6RGZOzzgnLDQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuEInpzSnLDT"
      },
      "source": [
        "# Cell 2: Imports and utilities\n",
        "import os, time, json, threading\n",
        "from typing import List, Dict, Any\n",
        "from flask import Flask, request, jsonify\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Helper to safely serialize numpy arrays to JSON\n",
        "class NpEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return super().default(obj)\n"
      ],
      "execution_count": 2,
      "outputs": [],
      "id": "fuEInpzSnLDT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "effDC2QanLDU"
      },
      "source": [
        "# Cell 3: Knowledge Base (embedded)\n",
        "KNOWLEDGE_BASE = [\n",
        "    {\"id\": \"doc1\", \"title\": \"Shoplite User Registration and Account Management\", \"content\": \"To create a Shoplite account, users must visit the registration page and provide a valid email address, password, and basic profile information. Email verification is required within 24 hours. Users can choose between: - Buyer accounts (free) - Seller accounts (requires business verification and tax information). Account Management Features: Update personal information, Change passwords, Set security questions, Manage notification preferences, Deactivate accounts (requires email confirmation; may affect active orders/subscriptions). Buyer Access: product browsing, purchasing, order tracking, reviews. Seller Access: seller dashboard, inventory management, order processing, analytics. Security Measures: two-factor authentication recommended, password recovery via email and phone verification.\"},\n",
        "    {\"id\": \"doc2\", \"title\": \"Shoplite Product Search and Filtering Features\", \"content\": \"Shoplite provides a powerful search engine: Search Capabilities: keyword queries, category selection, brand filters. Filtering Options: price range, rating, availability, seller location, shipping speed, promotions, eco-friendly options. Features: Autocomplete suggestions, Spelling correction, Save searches & alerts, Faceted navigation, Optimized for large catalogs with real-time indexing, Mobile responsive interface.\"},\n",
        "    {\"id\": \"doc3\", \"title\": \"Shoplite Shopping Cart and Checkout Process\", \"content\": \"Add multiple items from different sellers; Review quantities, apply promo codes/gift cards; Cart preserved across sessions for logged-in users. Checkout Steps: 1. Shipping selection (standard, expedited, same-day) 2. Payment selection (credit/debit cards, digital wallets, cash-on-delivery) 3. Order confirmation. Security & Processing: PCI-DSS compliant payment gateways, Real-time stock updates, Order confirmation emails with tracking, Seller notifications for new orders, Integrated returns and refunds system.\"},\n",
        "    {\"id\": \"doc4\", \"title\": \"Shoplite Payment Methods and Security\", \"content\": \"Accepted Payment Methods: credit/debit cards, PayPal, Apple Pay, Google Pay, local solutions. Security Measures: SSL encryption, PCI-DSS compliance, fraud detection, two-factor authentication, sensitive info encrypted in transit and at rest. Other Features: digital wallet integration, structured dispute/chargeback process, seller payments after order confirmation.\"},\n",
        "    {\"id\": \"doc5\", \"title\": \"Shoplite Order Tracking and Delivery\", \"content\": \"Real-time tracking with confirmation emails and unique tracking number. Stages: confirmed -> processing -> shipped -> in transit -> delivered. Delivery modification requests (seller approval required). International shipments display customs/import duties. Optimized logistics with estimated arrival and delay notifications. Support assistance for lost/delayed packages.\"},\n",
        "    {\"id\": \"doc6\", \"title\": \"Shoplite Return and Refund Policies\", \"content\": \"Return Period: typically 30 days from delivery. Process: select order/item, specify reason, use prepaid label if eligible. Refunds: processed in 5â€“7 business days to original payment method. Digital/personalized items may have exceptions. Automated order status updates. Sellers must comply with policies to maintain ratings. Dispute resolution available.\"},\n",
        "    {\"id\": \"doc7\", \"title\": \"Shoplite Product Reviews and Ratings\", \"content\": \"Buyers rate products on a five-star scale and leave comments. Reviews moderated for compliance. Sellers can respond to reviews. Ratings influence search ranking. Verified purchase badges for authenticity. Aggregate ratings provided. Review analytics available for sellers.\"},\n",
        "    {\"id\": \"doc8\", \"title\": \"Shoplite Seller Account Setup and Management\", \"content\": \"Create seller account with business documents and tax verification. Seller Dashboard: inventory management, order processing, sales analytics. Product listing via individual or bulk upload (CSV/API). Profile customization: branding, policies, shipping, returns. Notifications: new orders, low stock, inquiries. Pricing, promotions, and shipping fee management. Performance metrics tracked; third-party integrations supported.\"},\n",
        "    {\"id\": \"doc9\", \"title\": \"Shoplite Inventory Management for Sellers\", \"content\": \"Track stock levels, reorder thresholds, and availability in real-time. Low-stock alerts. Bulk imports supported. Variants (size, color, bundle) supported. Inventory reports for trends and seasonal demand. Manage warehouses and shipping locations.\"},\n",
        "    {\"id\": \"doc10\", \"title\": \"Shoplite Commission and Fee Structure\", \"content\": \"Commission fees per product category. Additional fees: premium listings, promotions, special services. Transparent notifications in dashboard. Payments made after commission deduction (weekly/bi-weekly). Transaction reports available. Pricing guidance provided.\"},\n",
        "    {\"id\": \"doc11\", \"title\": \"Shoplite Customer Support Procedures\", \"content\": \"Support via live chat, email, phone, and AI chatbot (24/7). Ticket categorization: orders, payments, returns, technical, account management. Unique tracking IDs. Backend integration for order/payment info. Dedicated seller support channel. Help center with guides, FAQs, videos. Fast, transparent, fair resolution.\"},\n",
        "    {\"id\": \"doc12\", \"title\": \"Shoplite Mobile App Features\", \"content\": \"iOS & Android support. Browse, filter, add to cart, purchase. Push notifications for promotions/order updates. Barcode scanning and QR code payments. Mobile wallets, fingerprint, Face ID login. Seller management on-the-go. Offline caching for previously loaded content. Intuitive, responsive, accessible interface.\"},\n",
        "    {\"id\": \"doc13\", \"title\": \"Shoplite API Documentation for Developers\", \"content\": \"RESTful API endpoints: product catalog, orders, accounts, inventory. OAuth 2.0 authentication. Rate limiting (higher for verified partners). Detailed docs: request/response, parameters, error codes. Webhooks for real-time events. Sandbox environment for testing. Versioned API with backward-compatible updates.\"},\n",
        "    {\"id\": \"doc14\", \"title\": \"Shoplite Security and Privacy Policies\", \"content\": \"Data Protection: TLS encryption, AES-256 at rest, authorized access. Two-factor authentication & strong passwords. GDPR & CCPA compliance. Security monitoring for suspicious activity. Clear privacy policies: data collection, usage, third-party sharing. Policy change notifications; user control over data.\"},\n",
        "    {\"id\": \"doc15\", \"title\": \"Shoplite Promotional Codes and Discounts\", \"content\": \"Sellers create promotions: discount codes, seasonal sales, bundle offers. Code types: percentage, fixed, conditional. Start/end dates, usage limits, minimum purchase configurable. Automatic verification at checkout. Analytics: redemption, revenue, engagement. User notifications for active promotions. Special events highlighted on homepage/app. Compliance with platform policies.\"}\n",
        "]\n"
      ],
      "execution_count": 3,
      "outputs": [],
      "id": "effDC2QanLDU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox97pQV-nLDW"
      },
      "source": [
        "# Cell 4: Prompts embedded as Python dict (converted from assistant-prompts.yml)\n",
        "PROMPTS = {\n",
        "    \"version\": \"1.0\",\n",
        "    \"created\": \"2025-09-23\",\n",
        "    \"author\": \"Joseph Chamoun\",\n",
        "    \"base_retrieval_prompt\": {\n",
        "        \"role\": \"You are a helpful Shoplite customer service assistant.\",\n",
        "        \"goal\": \"Provide accurate answers using only the provided Shoplite documentation.\",\n",
        "        \"context_guidelines\": [\"Use only information from the provided document snippets\", \"Cite specific documents when possible\"],\n",
        "        \"response_format\": \"Answer: [Your response based on context]\\nSources: [List document titles referenced]\\n\",\n",
        "    },\n",
        "    \"multi_doc_synthesis\": {\n",
        "        \"role\": \"You are an expert Shoplite support agent who synthesizes multiple documents.\",\n",
        "        \"goal\": \"Combine information from multiple retrieved documents to create a concise, accurate answer.\",\n",
        "        \"context_guidelines\": [\"State which documents you used\", \"When information conflicts, show both options and recommend the safer/default one\"],\n",
        "        \"response_format\": \"Answer: [Synthesis]\\nSources: [Doc titles]\\nConfidence: [High|Medium|Low]\\n\",\n",
        "    },\n",
        "    \"refusal_when_no_context\": {\n",
        "        \"role\": \"You are a safety-conscious assistant.\",\n",
        "        \"goal\": \"Refuse to answer if no relevant context is found in the knowledge base and ask for clarification or external data.\",\n",
        "        \"context_guidelines\": [\"If top retrieved documents have low similarity (< threshold), return a refusal\", \"Suggest the user provide more details or check the Shoplite help center\"],\n",
        "        \"response_format\": \"Answer: I don't have enough information in the Shoplite docs to answer that. Please provide more details or check [Help Center].\\n\",\n",
        "    }\n",
        "}\n"
      ],
      "execution_count": 4,
      "outputs": [],
      "id": "Ox97pQV-nLDW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577,
          "referenced_widgets": [
            "91c12bd3cf8c44eabcbcc75f13b955c9",
            "449dc41a1a2041d98238f5750800012e",
            "04640d095401491e97e1ba5381e3a64f",
            "f349b928339a47f39cab8d091b46fc6f",
            "9787011415484fc7a74fa9e3b45d93c6",
            "98a2cea61b1542b59e0df5c3f41c505a",
            "81a3015952c343aaae8d6a115a9b877e",
            "c95efadafe704e58af9a35d451a0be1f",
            "3283b7da37a24fd1a4f25e4f5e4640ce",
            "57531eca046544659080c8221e2c587c",
            "2f8d9893506349a7a7290247802d9152",
            "6de83c91c97741278127345aee4eac4f",
            "b64690c3de0942369c0a0681ba0a154f",
            "82d75c9dc1e14660b7029a3719abba48",
            "fc8d46a749254c78b08a4b6bc2df1e1b",
            "e93e6085f25249399b814b9232087ba7",
            "cab348512ca74fb5b5066eb6ad053ea3",
            "d47926e997b5431d8f1ddea5cbb28ee6",
            "98231446a7f94511a976b7b5722a232d",
            "22ca8a7fb906484baea4b508bb12a75d",
            "bc0f73ff83154f1bb322c2681527f880",
            "1977b8f78a7a4af7aa38c4367e5bcc3c",
            "74830e3100724e7782882b323c83c191",
            "0956a7136d3142de8f4ba02ca65bf15e",
            "f05d2d2e1fba4f3391c076fa0d7ea8b8",
            "362a34c0e67e4081ab737cd187d11f19",
            "d8d35ae30ee5488a88f048df99a6d621",
            "d076b1028cff459f8aa18e8fc2939a96",
            "8271a5eceb62407e862cd155e61e0287",
            "bd4113f83a0c4643b4461306662700b6",
            "b0e20fd59dd54978935fdbe0014a2100",
            "9b834fc477044e9abfdec44987e2bb56",
            "e8345ca79d7a4c53b2f12c5ef7ae3043",
            "89d416a0a11747838d65bf9a6aed97e1",
            "27d6bd0d91b9453b9970a3f43876f450",
            "19200b9a44a54dfeb19ab1be901712a4",
            "a36af3a002be4e36bc480db6a8b1eb13",
            "0de4826d17ca4b92ba4718bc8bfacae4",
            "ead7646af0a6403ea40b8671c9e8a7f4",
            "9992f64a26e44a23a4e432a16274ea35",
            "446a0a47c4a843099df0b11927a7614f",
            "e1dcdfc5b94e4076b3fe38d5cb223894",
            "ef05fb0763794827b0eb6120df912241",
            "6aa601b0910e4a1cbdb3f9ddfa3fe078",
            "cfb2b011737548ba8c11a839a682c1cb",
            "b468e5602d6045aba73ef244bb529123",
            "7a3d86b1eb034db987804cc9526b5654",
            "829e4d58cd3d47768a2aa4b46987692f",
            "173fb38283b84636a352d745f4ea3b96",
            "18e42ba2b2df4afebf934db04a165fdb",
            "79b9774b34f2452a8119b08841bfd29a",
            "3aac6e03023c40bc9160b5a9ab378101",
            "701d57cbed6242738b09454adb5899d7",
            "854d27ab630f45a0a8e319c8e21cb66d",
            "2c04fc4d031c4e60a979b86dfef55888",
            "2b333792b98545188e95ae3a1791c43f",
            "b0d668eb6ed2431a8d2c68835dd50219",
            "0fbb716ba4b14466b2bb281ce139a30a",
            "896b50394f4647fc97190601da0a8c78",
            "9ee1c48272444502958d18409c93d14c",
            "7d6dcaeb153b4543a3080e4ea88e53ae",
            "c3245f3d41c3418ca543eb21df2716ff",
            "7a75cbdaf5c047e39a7053b4e9ea1173",
            "94bfb85cb6c84f968cb12055ef973b9c",
            "3daa7944c49641439c68587368dc7aa8",
            "c53d49fcc912402e91d1ed62e74ee7e1",
            "eb349378bbcd40d29a9f68d18963a673",
            "f30954abcaa143b5bc0281176cfc068e",
            "09e4ee85db2142f389300e285c33a682",
            "98241623352e4346a1efddfe00e3391c",
            "f1f2e12073e346d1ad2bafca19b1839f",
            "a45abe8b180241459e0af9b460e2d65e",
            "1dced8d219f24f239621408f26bfaecf",
            "fb2c4c83b1b24b93863939490f5103fe",
            "4af4cd3a09804933bdff43cd19cb3023",
            "bceb9f7b943e4cf3a99dabad2b27a480",
            "21a65a5d0e4a4d449daa965fdc40e79d",
            "6095394d42f64dffaee78e3e0a2b4f8f",
            "cafb83926b724992a8d0a5cef58a2f7b",
            "0d19f8e3e83741a3a19f504a69970f0f",
            "636db1de23044c9485cca65bf9c65d4d",
            "66f18e5486704e179dba705b9e7b0afa",
            "cf4cac58cc0c454bb39e18bd8e685f26",
            "c0d92aa0710c4936b68309dad64fd586",
            "fdc70c0684c044dfb9bbdcced4e50aac",
            "e4d0d17194c5480faff844e3b9f7e22f",
            "96b1e77133e74462b64ff7326fca1dfc",
            "9af9dccf9238425d8aeb37872304af5d",
            "a06e42df238c4de09bc28881b351a93b",
            "15cd7f2406d941149b2910a077834885",
            "155a8de404b441db894a92ac813c64bc",
            "690d1c6f94954c19ad0ca9d266fde01b",
            "5086eca178984d0b99c7e09182032539",
            "53964eadbf9e4de3a25a1b38eba04b4e",
            "05fa5095d2284dcfaa6ec5274576fb64",
            "c7b69296a03f42e583567a77e16c61ad",
            "2844dffafe4443fe9f56cfc69a7bf3d4",
            "aa6fd88511c140dd813f98605ec9be35",
            "c34c136110da4526b749f6a95356aae3",
            "372f2e48d93e40e59f1b9ef7129031f8",
            "b707ccd42b58409f81c8dbd5ca27c28e",
            "7b6c9ed1d394453f9fec51f282dc4dab",
            "4767ecc07a124d1b88bd961c19a0a0e8",
            "c21bc81fa0444c889d1e8a5475be8d54",
            "11cc7dd0d26f46cbb0583be7ce0fb361",
            "e9410f51638b4a698e7e7d7f90f0ed20",
            "0932d219c31646909ea124394077cfa5",
            "544f687faf4340d9995772a55a72348d",
            "eed359d9a16d4a35b11add21d5332353",
            "de173b13425c4963a6823fffa6a9d405",
            "a3a05ef5cb9a4cfe924b1088bfde41ab",
            "d49ce2ede94d4c74944804535e7e3cea",
            "5a5a39cdea4a408cab0891c6a929d8a6",
            "4d05948905d74ea3964a0749daf2101b",
            "47d3ca2bff3a44f580a29d8924b2fc9c",
            "64c4d5f7a4204d18b0dcc3bc13f5a76a",
            "9fc7a929e5f9474084427270f0305f85",
            "923e6f5a0c134d9080bcfbfaaeed06ab",
            "84020259546547d985949c93ae3375cc",
            "e38ed1bf639149f28e05574dc9736f07",
            "f1d1f420181043d5aa111d2166d12e75",
            "34a31d674395414c8ff08fa9c2769cc0",
            "da4374289acd4341a044ff007bbdddff",
            "6bc82b061d1f486191d894c4ad204075",
            "f419fdc278554c869dc3dae848e17fc9",
            "ca5257f6d0014b5db7d46f8a6d7cc496",
            "4dbc17f7007f44fe894a1e2ed39a8acc",
            "fe2df91dbd1e494a85c5a8c6f9a597e5",
            "d3fdcfec65584aa3a9552829024db897",
            "9d525093d42044c48a1ffeadd3c88a63",
            "91cee3c4d88142be9e477b56857b5e30",
            "e3e3666fd94a4a8dba05cb31b87cb6b6"
          ]
        },
        "id": "K9zwZ3MlnLDX",
        "outputId": "ac325825-65e3-4e94-bb9e-3422e013cd46"
      },
      "source": [
        "# Cell 5: Build embeddings and FAISS index\n",
        "EMBED_MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "print('Loading embedding model:', EMBED_MODEL_NAME)\n",
        "embed_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
        "\n",
        "DOCUMENT_TEXTS = [d['title'] + '\\n\\n' + d['content'] for d in KNOWLEDGE_BASE]\n",
        "DOC_IDS = [d['id'] for d in KNOWLEDGE_BASE]\n",
        "\n",
        "print('Encoding documents...')\n",
        "doc_embeddings = embed_model.encode(DOCUMENT_TEXTS, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "def normalize_embeddings(embs):\n",
        "    norms = np.linalg.norm(embs, axis=1, keepdims=True)\n",
        "    return embs / np.clip(norms, a_min=1e-10, a_max=None)\n",
        "\n",
        "doc_embeddings = normalize_embeddings(doc_embeddings)\n",
        "d = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(d)\n",
        "index.add(doc_embeddings)\n",
        "print(f'FAISS index created with {index.ntotal} vectors (dim={d})')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91c12bd3cf8c44eabcbcc75f13b955c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6de83c91c97741278127345aee4eac4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74830e3100724e7782882b323c83c191"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89d416a0a11747838d65bf9a6aed97e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfb2b011737548ba8c11a839a682c1cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b333792b98545188e95ae3a1791c43f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb349378bbcd40d29a9f68d18963a673"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6095394d42f64dffaee78e3e0a2b4f8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a06e42df238c4de09bc28881b351a93b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "372f2e48d93e40e59f1b9ef7129031f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3a05ef5cb9a4cfe924b1088bfde41ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding documents...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34a31d674395414c8ff08fa9c2769cc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index created with 15 vectors (dim=384)\n"
          ]
        }
      ],
      "id": "K9zwZ3MlnLDX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoLI92xvnLDX",
        "outputId": "b3d75103-2903-454b-defa-8777d6ab4ea5"
      },
      "source": [
        "# Cell 6: Retrieval functions\n",
        "def retrieve_docs(query: str, top_k: int = 3):\n",
        "    q_emb = embed_model.encode([query], convert_to_numpy=True)\n",
        "    q_emb = normalize_embeddings(q_emb)\n",
        "    scores, indices = index.search(q_emb, top_k)\n",
        "    results = []\n",
        "    for score, idx in zip(scores[0], indices[0]):\n",
        "        if idx < 0 or idx >= len(KNOWLEDGE_BASE):\n",
        "            continue\n",
        "        doc = KNOWLEDGE_BASE[idx]\n",
        "        results.append({\n",
        "            'id': doc['id'],\n",
        "            'title': doc['title'],\n",
        "            'content': doc['content'],\n",
        "            'score': float(score)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Quick test (optional)\n",
        "print(retrieve_docs('How do I create a seller account on Shoplite?', top_k=3))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'id': 'doc1', 'title': 'Shoplite User Registration and Account Management', 'content': 'To create a Shoplite account, users must visit the registration page and provide a valid email address, password, and basic profile information. Email verification is required within 24 hours. Users can choose between: - Buyer accounts (free) - Seller accounts (requires business verification and tax information). Account Management Features: Update personal information, Change passwords, Set security questions, Manage notification preferences, Deactivate accounts (requires email confirmation; may affect active orders/subscriptions). Buyer Access: product browsing, purchasing, order tracking, reviews. Seller Access: seller dashboard, inventory management, order processing, analytics. Security Measures: two-factor authentication recommended, password recovery via email and phone verification.', 'score': 0.7689905166625977}, {'id': 'doc8', 'title': 'Shoplite Seller Account Setup and Management', 'content': 'Create seller account with business documents and tax verification. Seller Dashboard: inventory management, order processing, sales analytics. Product listing via individual or bulk upload (CSV/API). Profile customization: branding, policies, shipping, returns. Notifications: new orders, low stock, inquiries. Pricing, promotions, and shipping fee management. Performance metrics tracked; third-party integrations supported.', 'score': 0.767737865447998}, {'id': 'doc3', 'title': 'Shoplite Shopping Cart and Checkout Process', 'content': 'Add multiple items from different sellers; Review quantities, apply promo codes/gift cards; Cart preserved across sessions for logged-in users. Checkout Steps: 1. Shipping selection (standard, expedited, same-day) 2. Payment selection (credit/debit cards, digital wallets, cash-on-delivery) 3. Order confirmation. Security & Processing: PCI-DSS compliant payment gateways, Real-time stock updates, Order confirmation emails with tracking, Seller notifications for new orders, Integrated returns and refunds system.', 'score': 0.5590235590934753}]\n"
          ]
        }
      ],
      "id": "yoLI92xvnLDX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6.5 (REPLACE): Hugging Face Login (runtime input; no hardcoded token)\n",
        "# NOTE: Do NOT hardcode tokens in the notebook. Enter at runtime when prompted.\n",
        "from huggingface_hub import login\n",
        "\n",
        "hf_token = input(\"ðŸ”‘ Enter your Hugging Face token (paste it here; will not be saved in the notebook): \").strip()\n",
        "if not hf_token:\n",
        "    print(\"No token provided. Attempts to load private models may fail. Proceeding without login.\")\n",
        "else:\n",
        "    try:\n",
        "        login(hf_token)\n",
        "        print(\"Hugging Face login successful.\")\n",
        "    except Exception as e:\n",
        "        print(\"Hugging Face login failed:\", e)\n",
        "        print(\"If you can't load protected models, try switching to a publicly available model.\")\n"
      ],
      "metadata": {
        "id": "O6bNRdRwn0lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3337aad1-dcf3-47a7-bf97-b2899df87bee"
      },
      "id": "O6bNRdRwn0lq",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”‘ Enter your Hugging Face token (paste it here; will not be saved in the notebook): hf_example\n",
            "Hugging Face login successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488,
          "referenced_widgets": [
            "0d81400381894525a34309c420f74fff",
            "e2ca2e0a68fa4129b6747201329851f6",
            "ba3f5d79e04a4a84a5b7dac5c9a5bc0c",
            "67a766f960aa44f9984eed0f055a2167",
            "6a52c52f36bd46e39530b44743682d81",
            "9893b404919f43eba31ec256d42dc26a",
            "ab352aefbaff4e1cb1a4b5c8191bcea0",
            "d3e14cc947ed4c1b8fe26502375aff4c",
            "37897ec7b30440abafe84663faf69cf8",
            "98b23eb80be3475789713ed4b08cbd5b",
            "c8d7ed19c55b461d835eaf7b4d0869ae",
            "863b28561eaa4af4994fcfdf52e15133",
            "fad8c28622be4f3099816502841de71c",
            "427fb21897814aa8b703e0333c14fe69",
            "b02d0646a59140c9a93129530e42efb9",
            "7b04165a88484575a51805ea44a1ab4b",
            "7a36e63f8221463b80401044af851e4f",
            "141e367b4e1f4f98875091649115ddac",
            "1f98e21879d24fd19aaa459d87a63612",
            "7a2536102f794252b5151d6d5bb19486",
            "a9ce01475cbe4d7b9a138f17c10ce30e",
            "9f602096093044dfbcce2765612d4800",
            "52e91470eeaa42cc9e2561bfe2d84a40",
            "6958afef252248b8b39fd9af8a604895",
            "3a194bc3fe8c45928d3bd011cfadf813",
            "0f7e2f0da9e84022bb9961f86f707b26",
            "53bdf8a24dd740c497693f5aa107adee",
            "e362dbef987047dd8dc1d46fdf802c24",
            "d25198c06937471daff24a0d78887b4d",
            "77731e03db5446d4840323dcf845541b",
            "847ee8ec47e648e0aa48775819122748",
            "547beb2c3a4147b1822e753f86f04f45",
            "6798ad20941f4b7198c5b55530709f41",
            "a7620aa62db54963a32fa0bd46cab905",
            "6425408fd7ca487db1183c3139acbbd2",
            "4b5e64acc0a04612921d6c2859f30210",
            "046ec88908f047a38607d33d66a9e16e",
            "837cb9b564844a0bb7f6ef263050c3ba",
            "c646d919ba2f40e0b6524f0aca1d88f6",
            "bcaacafde4694ea49f721aeff5ffac58",
            "63d2b362a15043a4a1fc477ec5b5c5c8",
            "1ee71e7828c244ae85e9b5a118465a90",
            "0e0135b3e60141189643009474a38dca",
            "4aeeafcf6df0423aa534620cdd897cb8",
            "c254ba63a7c34166afcd1e643fd35b27",
            "3311093d85e847b99b465f36cbb16a6b",
            "d57b3e80c06947a7b11257df6204431e",
            "dbd11455d83242cfadd6bfe5ea65756e",
            "7c2bc79f2178451d827017d5406318b0",
            "b3ec29f4125f41d5a233d136764761b8",
            "6a35a9c595ea4d9fb3332afa3d8935c3",
            "1cf7906af6b84ddab99c7776bd8fc80e",
            "46a9369fb71b44929291bf545969fc79",
            "d525986365f0448ca7b1e851809d7151",
            "5c3cdcd278c144069a3dee2726d301c4",
            "bf41a84dc0674963aa6830a26bbd6d2b",
            "44030e4630ba45218d26f2dad9b1dde8",
            "54737cd85ea7429ab91b5031b30ae470",
            "f10aa1d65b134e9282e1c7241d36d49a",
            "46d2145fa66d4bbc9e24165b33ac81b8",
            "c6c3c08defe8433a882a661b5355876a",
            "7033efe2975d43a8ab490efa746b7eb9",
            "d6e5230fb59645e391e85283e95bd4f5",
            "a44e7bbd15964e3480eb5967d2d2591d",
            "f275667ebbf648298f6575151e8abaea",
            "537974185e494379a18a4a6d69686376",
            "309196f3571745979e06c7416ccf1194",
            "10a5ce8e4b1e4bd3be059bb62b53f53d",
            "708d98c6af704e7eb7d1663e9ba17677",
            "1b0ca0a29391415c95e00539064d66e9",
            "1b56e5ef43164ea9932126faf74b40e2",
            "729c2576ba53410b8ed2101c768cb5ff",
            "30bf0d22c34e45e0adce0443789e3a46",
            "82fcf08e3f4947d595fc83673ae53e92",
            "98e0576ca74746cd809e77729433d0cc",
            "6d03656dcb8c4a30a093d9468102fa24",
            "a2581f69e26e4530bcf930ebf463dea3",
            "285da7f83c3743f4b78a6473ca4fb749",
            "472c449bacf548169d2c569179782569",
            "5803951085c34bb5b819862cb6e0fdb0",
            "7d5ab68b51cb4b769760a2ef3bb933b5",
            "3506ac573f5b4449aa240bd9a03d43ab",
            "3c25e9010b02434f8b2aadabba96f731",
            "c06ed77cda5d419cabc3c3896a5efc40",
            "41aca2657d474b928952a4571629eb9b",
            "bd5e5e51ff4349f48df4a22129cc17e7",
            "a9296a0f114e41a2bdd5bc722883f213",
            "56565cc89853431ba2d01b3b917cbe56",
            "cde90f4b730a408d9243d44519d1cf88",
            "38423aba8b0548efacc5aebd65c7c168",
            "10b05ddd36584d70a09626015da40e59",
            "1d678e2b466d4ba383ec7c6c46851667",
            "874fe51af7d74d54bd98c58393cbf2a0",
            "ab74046f3b454ed8989ab3628be59d69",
            "5dbf63a0c601416093f0d1c5e04b5f6d",
            "63248801d30346d7bc1c7e3097a97d40",
            "a1d9ed1d3cf74ca3b3208b3f3bcc6a10",
            "a1ab692b024a43a19a2d304905803fd7",
            "028d1cb944814c31a51618b360ad802b",
            "e95989756bf5406ca30925514a9bd3a5",
            "ee590484b686461ea441e5b49b5e3084",
            "18bedebce55c4048ab0bf24529051059",
            "a67dc5ebc0394454b34791103f6415ca",
            "aec0df9ec0964bac8f7e7cc87361a2b3",
            "676f93a5e20b4f23b858d250ad7e25a7",
            "9541cc4b96ed40c1ba1773750e9b4f20",
            "c24495be965d42b3b8bbb80bc6a62e10",
            "ab01e0d65ed24310be1785b7fbb26a91",
            "eff526151bab43838a6fcc202050adf2",
            "9e67c15bffd744e58ceae5b465201b01",
            "050b1e8446a74ee191500acf2bcee389",
            "5115e7de62bc464ba0adfa69382d655f",
            "b4b4e1534ae34466a8adad00494a38c3",
            "824806a5e727476286f1ef8f00d519e9",
            "44b9531d4fe6409a84cc8ab7376f6753",
            "25dde8c502e04e51b18873d7263434de",
            "71ceefaa885446f39a6e2223a6061068",
            "a7c57d7645bf4d7bba4976bada59b936",
            "9e95f8e454ef457ca812bbfd41d9562b",
            "b720427feb754fb9b3d2e8052dd2b635",
            "b915121dded44aed9493e38fb32e40e3",
            "b97c14b15cca44fe9d567de319d46c2f",
            "e8392467cbc143b29bac95af48d2c2d4",
            "e82d68c5f7d44f78a9ccae2f0c1c3a71",
            "0a773df740d24ea8af3926ba46ab7261",
            "c56baf382dbe44c7add978617aafb1ab",
            "351a22c682454f17b24b680086f3f32d",
            "8d97de4ddf8747c8b7f447504d8c7d2f",
            "d168d3dda3da48aaa5f8cbf7c12261b1",
            "5164584f79734a419f0f9f884c28ded1",
            "891b23e33ced463eac62030535424837",
            "9a8aa55f6f02496aa524e757c03466b6"
          ]
        },
        "id": "tfyCXmAPnLDY",
        "outputId": "92f469b8-24f5-4f7a-d040-8d9c8a6be771"
      },
      "source": [
        "# Cell 7 (REPLACE): Model loading with modern quantization config + safe fallbacks\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"  # preferred (may require HF access)\n",
        "FALLBACK_MODEL = \"tiiuae/falcon-7b-instruct\"     # a smaller public instruct model used as fallback\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"Attempting to load model:\", MODEL_NAME)\n",
        "print(\"CUDA available:\", use_cuda)\n",
        "\n",
        "model = None\n",
        "tokenizer = None\n",
        "\n",
        "def try_load_model(model_name, quant_config=None, dtype=torch.float16):\n",
        "    \"\"\"Attempt to load the model with optional quantization config.\"\"\"\n",
        "    try:\n",
        "        tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "        if quant_config is not None:\n",
        "            mdl = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name,\n",
        "                device_map=\"auto\" if use_cuda else None,\n",
        "                quantization_config=quant_config,\n",
        "                torch_dtype=dtype,\n",
        "                low_cpu_mem_usage=True,\n",
        "            )\n",
        "        else:\n",
        "            mdl = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name,\n",
        "                device_map=\"auto\" if use_cuda else None,\n",
        "                torch_dtype=dtype,\n",
        "                low_cpu_mem_usage=True,\n",
        "            )\n",
        "        mdl.eval()\n",
        "        return tok, mdl\n",
        "    except Exception as e:\n",
        "        print(f\"Load failed for {model_name}: {repr(e)}\")\n",
        "        return None, None\n",
        "\n",
        "# Prepare a BitsAndBytesConfig for 8-bit (modern API)\n",
        "try:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_8bit=True,          # prefer 8-bit quantization when available\n",
        "        llm_int8_threshold=6.0      # heuristic threshold (tweak if needed)\n",
        "    )\n",
        "except Exception:\n",
        "    # In case BitsAndBytesConfig import signature differs on some versions\n",
        "    bnb_config = None\n",
        "\n",
        "# 1) Try to load preferred model with quantization\n",
        "if bnb_config is not None:\n",
        "    print(\"Trying quantized load with BitsAndBytesConfig...\")\n",
        "    tokenizer, model = try_load_model(MODEL_NAME, quant_config=bnb_config, dtype=torch.float16)\n",
        "else:\n",
        "    print(\"BitsAndBytesConfig not available; attempting standard/float16 load...\")\n",
        "    tokenizer, model = try_load_model(MODEL_NAME, quant_config=None, dtype=torch.float16)\n",
        "\n",
        "# 2) Fallback: try without quant or try the fallback model\n",
        "if model is None:\n",
        "    print(\"Primary model load failed. Trying fallback public model:\", FALLBACK_MODEL)\n",
        "    tokenizer, model = try_load_model(FALLBACK_MODEL, quant_config=bnb_config, dtype=torch.float16)\n",
        "    if model:\n",
        "        print(\"Fallback model loaded:\", FALLBACK_MODEL)\n",
        "    else:\n",
        "        print(\"Fallback model also failed. The notebook will still run retrieval, but LLM responses will be disabled.\")\n",
        "        model = None\n",
        "        tokenizer = None\n",
        "\n",
        "# Final status\n",
        "if model is not None and tokenizer is not None:\n",
        "    print(\"Model and tokenizer loaded successfully.\")\n",
        "else:\n",
        "    print(\"No model loaded. Generation endpoints will return retrieval-only responses.\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load model: meta-llama/Llama-3.1-8B-Instruct\n",
            "CUDA available: True\n",
            "Trying quantized load with BitsAndBytesConfig...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d81400381894525a34309c420f74fff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "863b28561eaa4af4994fcfdf52e15133"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52e91470eeaa42cc9e2561bfe2d84a40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7620aa62db54963a32fa0bd46cab905"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c254ba63a7c34166afcd1e643fd35b27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf41a84dc0674963aa6830a26bbd6d2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "309196f3571745979e06c7416ccf1194"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "285da7f83c3743f4b78a6473ca4fb749"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cde90f4b730a408d9243d44519d1cf88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e95989756bf5406ca30925514a9bd3a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "050b1e8446a74ee191500acf2bcee389"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b97c14b15cca44fe9d567de319d46c2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully.\n"
          ]
        }
      ],
      "id": "tfyCXmAPnLDY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyO4x8ZQnLDY"
      },
      "source": [
        "# Cell 8: Final optimized version with proper text extraction\n",
        "import torch\n",
        "\n",
        "TEMPERATURE = 0.7\n",
        "MAX_TOKENS = 120\n",
        "SIMILARITY_THRESHOLD = 0.25\n",
        "\n",
        "def build_prompt_from_retrieval(query: str, retrieved_docs: List[Dict[str, Any]]):\n",
        "    \"\"\"Builds prompt using top 5 documents.\"\"\"\n",
        "    docs_text = \"\"\n",
        "    for i, doc in enumerate(retrieved_docs[:5], 1):\n",
        "        content = doc['content'][:200] + \"...\" if len(doc['content']) > 200 else doc['content']\n",
        "        docs_text += f\"\\n[Document {i}: {doc['title']}]\\n{content}\\n\"\n",
        "\n",
        "    prompt = (\n",
        "        f\"You are a helpful Shoplite customer service assistant.\\n\\n\"\n",
        "        f\"Use these documents to answer:{docs_text}\\n\\n\"\n",
        "        f\"Question: {query}\\n\"\n",
        "        f\"Answer in 2-3 sentences:\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def generate_response(query: str, top_k: int = 5, temperature: float = TEMPERATURE, max_tokens: int = MAX_TOKENS, debug: bool = False):\n",
        "    \"\"\"Generate response with proper text extraction.\"\"\"\n",
        "\n",
        "    query_lower = query.lower().strip()\n",
        "\n",
        "    # Greetings\n",
        "    if any(greeting in query_lower for greeting in [\"hi\", \"hello\", \"hey\", \"good morning\"]):\n",
        "        if \"how are you\" in query_lower:\n",
        "            return {\"answer\": \"I'm here and ready to help! How can I assist you with Shoplite today?\", \"sources\": [], \"confidence\": \"High\"}\n",
        "        return {\"answer\": \"Hello! I'm here to help you with Shoplite. What would you like to know?\", \"sources\": [], \"confidence\": \"High\"}\n",
        "\n",
        "    # Help requests\n",
        "    if query_lower in [\"help\", \"can you help\", \"can u help me\", \"help me\"]:\n",
        "        return {\"answer\": \"Of course! I can help you with Shoplite registration, orders, payments, returns, seller accounts, and more. What specific information do you need?\", \"sources\": [], \"confidence\": \"High\"}\n",
        "\n",
        "    # Retrieve documents\n",
        "    retrieved = retrieve_docs(query, top_k=top_k)\n",
        "\n",
        "    if not retrieved:\n",
        "        return {\n",
        "            \"answer\": \"I don't have information about that. I can only answer questions about Shoplite's platform, features, and services.\",\n",
        "            \"sources\": [],\n",
        "            \"confidence\": \"Low\"\n",
        "        }\n",
        "\n",
        "    top_score = max(d['score'] for d in retrieved)\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Top similarity score: {top_score:.3f}\")\n",
        "\n",
        "    # Reject only truly irrelevant queries\n",
        "    if top_score < SIMILARITY_THRESHOLD:\n",
        "        return {\n",
        "            \"answer\": \"I'm sorry, that question appears to be outside my knowledge base. I can help with questions about Shoplite's registration, orders, payments, returns, seller accounts, product search, and customer support.\",\n",
        "            \"sources\": [],\n",
        "            \"confidence\": \"Low\"\n",
        "        }\n",
        "\n",
        "    # Adjusted confidence thresholds\n",
        "    if top_score >= 0.6:\n",
        "        confidence = \"High\"\n",
        "    elif top_score >= 0.4:\n",
        "        confidence = \"Medium\"\n",
        "    else:\n",
        "        confidence = \"Low\"\n",
        "\n",
        "    prompt = build_prompt_from_retrieval(query, retrieved)\n",
        "\n",
        "    if model is None:\n",
        "        answer_parts = []\n",
        "        for doc in retrieved[:3]:\n",
        "            sentences = [s.strip() + '.' for s in doc['content'].split('.') if s.strip()][:1]\n",
        "            answer_parts.extend(sentences)\n",
        "        answer = ' '.join(answer_parts[:3])\n",
        "        return {\"answer\": answer, \"sources\": [d['title'] for d in retrieved[:3]], \"confidence\": confidence}\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors='pt', truncation=True, max_length=1536)\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            max_new_tokens=max_tokens,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.3,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    generated_ids = outputs[0][inputs['input_ids'].shape[1]:]\n",
        "    raw_text = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Raw generated text: {raw_text[:200]}\")\n",
        "\n",
        "    # Extract meaningful content - take first 3 sentences\n",
        "    sentences = []\n",
        "    current = \"\"\n",
        "\n",
        "    for char in raw_text:\n",
        "        current += char\n",
        "        # End of sentence markers\n",
        "        if char in '.!?' and len(current.strip()) > 15:\n",
        "            sentences.append(current.strip())\n",
        "            current = \"\"\n",
        "            if len(sentences) >= 3:\n",
        "                break\n",
        "\n",
        "    # Join first 2-3 sentences\n",
        "    text = ' '.join(sentences[:3])\n",
        "\n",
        "    # Remove trailing incomplete sentence\n",
        "    if text and not any(text.endswith(p) for p in ['.', '!', '?']):\n",
        "        last_period = text.rfind('.')\n",
        "        if last_period > 0:\n",
        "            text = text[:last_period + 1]\n",
        "\n",
        "    # If still empty or too short, use extractive approach\n",
        "    if len(text) < 20:\n",
        "        top_doc = retrieved[0]\n",
        "        content_sentences = [s.strip() + '.' for s in top_doc['content'].split('.') if len(s.strip()) > 20][:2]\n",
        "        text = ' '.join(content_sentences)\n",
        "\n",
        "    return {\n",
        "        \"answer\": text,\n",
        "        \"sources\": [d['title'] for d in retrieved[:3]],\n",
        "        \"confidence\": confidence\n",
        "    }"
      ],
      "execution_count": 62,
      "outputs": [],
      "id": "pyO4x8ZQnLDY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kOWRtSjnLDZ",
        "outputId": "c4f662a7-1e63-4623-f0c4-b893e436cb3b"
      },
      "source": [
        "# Cell 9: Flask API with timeout protection\n",
        "from flask import Flask, request, jsonify\n",
        "import threading\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({'status': 'ok', 'model_loaded': model is not None, 'num_docs': len(KNOWLEDGE_BASE)})\n",
        "\n",
        "@app.route('/ping', methods=['POST'])\n",
        "def ping():\n",
        "    data = request.json or {}\n",
        "    text = data.get('text', 'Hello')\n",
        "    return jsonify({'reply': f'Pong: {text}'})\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    data = request.json or {}\n",
        "    query = data.get('query')\n",
        "    top_k = int(data.get('top_k', 3))\n",
        "    debug = data.get('debug', False)\n",
        "\n",
        "    if not query:\n",
        "        return jsonify({'error': 'missing query'}), 400\n",
        "\n",
        "    try:\n",
        "        result = generate_response(query, top_k=top_k, debug=debug)\n",
        "        return jsonify(result)\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "# Run Flask in background thread\n",
        "def run_flask():\n",
        "    app.run(host='0.0.0.0', port=5000, threaded=True)\n",
        "\n",
        "thread = threading.Thread(target=run_flask, daemon=True)\n",
        "thread.start()\n",
        "print('Flask server started (background thread).')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flask server started (background thread).\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        }
      ],
      "id": "8kOWRtSjnLDZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y180W8OYnLDZ",
        "outputId": "8716635e-6bfb-440d-ed7d-71914c1c2bc3"
      },
      "source": [
        "# Cell 10: ngrok tunnel setup (prompt for authtoken)\n",
        "print('\\n=== NGROK TUNNEL SETUP ===')\n",
        "ngrok_token = input('Enter your ngrok authtoken (paste it here): ').strip()\n",
        "if ngrok_token:\n",
        "    try:\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "        public_url = ngrok.connect(5000)\n",
        "        print('ngrok tunnel created at:', public_url)\n",
        "    except Exception as e:\n",
        "        print('Failed to create ngrok tunnel:', e)\n",
        "        public_url = None\n",
        "else:\n",
        "    print('No ngrok token provided; remember to set up a tunnel separately.')\n",
        "    public_url = None\n",
        "\n",
        "print('If public_url is not None, use it to call the /chat endpoint from outside Colab.')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== NGROK TUNNEL SETUP ===\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your ngrok authtoken (paste it here): 2tkzDe4CgyDZw0djJQnD9CjmBhL_3QgC9RJvVxjy59hwhWC3W\n",
            "ngrok tunnel created at: NgrokTunnel: \"https://f3fceec26a40.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "If public_url is not None, use it to call the /chat endpoint from outside Colab.\n"
          ]
        }
      ],
      "id": "Y180W8OYnLDZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRnXFizrnLDb",
        "outputId": "d02e63ac-33cf-4b65-e388-2fdc88e967ad"
      },
      "source": [
        "# Cell 11: Quick test examples (run after ngrok created and model loaded)\n",
        "print('Local health check:')\n",
        "try:\n",
        "    import requests\n",
        "    r = requests.get('http://127.0.0.1:5000/health', timeout=5)\n",
        "    print('Health:', r.json())\n",
        "except Exception as e:\n",
        "    print('Local health check failed:', e)\n",
        "\n",
        "if 'public_url' in globals() and public_url:\n",
        "    print(f'Call this externally: POST {public_url}/chat with JSON {{\"query\": \"How do I create a seller account on Shoplite?\"}}')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2025 17:27:53] \"GET /health HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local health check:\n",
            "Health: {'model_loaded': True, 'num_docs': 15, 'status': 'ok'}\n",
            "Call this externally: POST NgrokTunnel: \"https://f3fceec26a40.ngrok-free.app\" -> \"http://localhost:5000\"/chat with JSON {\"query\": \"How do I create a seller account on Shoplite?\"}\n"
          ]
        }
      ],
      "id": "BRnXFizrnLDb"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "r = requests.post(\n",
        "    \"http://127.0.0.1:5000/chat\",\n",
        "    json={\"query\": \"can u help me, how to register?\"}\n",
        ")\n",
        "\n",
        "print(r.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ3gzBBcsDAa",
        "outputId": "1b13784a-6521-4a79-fe0f-c8e30e07357d"
      },
      "id": "TQ3gzBBcsDAa",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2025 18:39:20] \"POST /chat HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': '``', 'confidence': 'Low', 'sources': ['Shoplite User Registration and Account Management', 'Shoplite Seller Account Setup and Management', 'Shoplite Mobile App Features']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Test with faster generation\n",
        "import requests\n",
        "import time\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"Testing with optimized generation...\")\n",
        "\n",
        "# Test a few queries\n",
        "test_queries = [\n",
        "    \"what is the company name\",\n",
        "    \"hi how are you can u help me?\",\n",
        "    \"your website name?\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Query: {query}\")\n",
        "    print('='*60)\n",
        "\n",
        "    try:\n",
        "        r = requests.post(\n",
        "            \"http://127.0.0.1:5000/chat\",\n",
        "            json={\"query\": query},\n",
        "            timeout=60  # Reduced timeout\n",
        "        )\n",
        "        result = r.json()\n",
        "        print(f\"Answer: {result.get('answer')}\")\n",
        "        print(f\"Sources: {', '.join(result.get('sources', []))}\")\n",
        "        print(f\"Confidence: {result.get('confidence')}\")\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(\"ERROR: Request timed out\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmZS2JpFxhGp",
        "outputId": "b4a456f4-ba7d-4a59-896d-a7ebbf393ebf"
      },
      "id": "cmZS2JpFxhGp",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2025 19:12:04] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2025 19:12:04] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2025 19:12:04] \"POST /chat HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with optimized generation...\n",
            "\n",
            "============================================================\n",
            "Query: what is the company name\n",
            "============================================================\n",
            "Answer: I'm sorry, that question appears to be outside my knowledge base. I can help with questions about Shoplite's registration, orders, payments, returns, seller accounts, product search, and customer support.\n",
            "Sources: \n",
            "Confidence: Low\n",
            "\n",
            "============================================================\n",
            "Query: hi how are you can u help me?\n",
            "============================================================\n",
            "Answer: I'm here and ready to help! How can I assist you with Shoplite today?\n",
            "Sources: \n",
            "Confidence: High\n",
            "\n",
            "============================================================\n",
            "Query: your website name?\n",
            "============================================================\n",
            "Answer: I'm sorry, that question appears to be outside my knowledge base. I can help with questions about Shoplite's registration, orders, payments, returns, seller accounts, product search, and customer support.\n",
            "Sources: \n",
            "Confidence: Low\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvjckuYKnLDc"
      },
      "source": [
        "# Notes & Troubleshooting\n",
        "\n",
        "- **Model load failures**: Llama 3.1 8B is large and may not load on free Colab GPUs or without HF access. If loading fails, switch `MODEL_NAME` to a smaller model or use `load_in_8bit=True` with bitsandbytes.\n",
        "- **Quantization**: Use `bitsandbytes` + `accelerate` for 8-bit loading. Some setups require configuring `~/.cache/huggingface` with tokens/credentials.\n",
        "- **Security**: Never commit your ngrok authtoken. Enter it at runtime when prompted.\n",
        "- **Persistence**: Colab runtimes are ephemeral; save `doc_embeddings.npy` and `kb.json` if you want to reuse them within the same session.\n",
        "\n",
        "If you want, I can now generate the `/src/chat-interface.py` CLI script that connects to the ngrok endpoint and demonstrates example queries."
      ],
      "id": "dvjckuYKnLDc"
    }
  ]
}
