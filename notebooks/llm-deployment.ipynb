{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc6rDVZgnLDK"
      },
      "source": [
        "# Shoplite RAG System - Complete Deployment\n",
        "\n",
        "**Week 3 Assignment - Joseph Chamoun**\n",
        "\n",
        "This notebook is fully self-contained and implements a complete RAG system for Shoplite customer service.\n",
        "\n",
        "## Features:\n",
        "- ‚úÖ 15 embedded knowledge base documents\n",
        "- ‚úÖ FAISS vector search with sentence-transformers\n",
        "- ‚úÖ Llama 3.1 8B (or fallback to smaller model)\n",
        "- ‚úÖ Structured YAML prompts integrated\n",
        "- ‚úÖ Flask API with /chat, /ping, /health endpoints\n",
        "- ‚úÖ ngrok tunnel with runtime token input\n",
        "- ‚úÖ Smart retrieval with confidence scoring\n",
        "\n",
        "**IMPORTANT**: Make sure to select GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU)"
      ],
      "id": "lc6rDVZgnLDK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGZOzzgnLDQ"
      },
      "source": [
        "# Cell 1: Install all dependencies\n",
        "print(\"üì¶ Installing dependencies... (this may take 2-3 minutes)\")\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q transformers accelerate bitsandbytes sentence-transformers faiss-cpu flask pyngrok\n",
        "print(\"‚úÖ Installation complete!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "6RGZOzzgnLDQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuEInpzSnLDT"
      },
      "source": [
        "# Cell 2: Imports\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import threading\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "\n",
        "print(\"‚úÖ All imports successful\")\n",
        "print(f\"üî• CUDA available: {torch.cuda.is_available()}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "fuEInpzSnLDT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "effDC2QanLDU"
      },
      "source": [
        "# Cell 3: Knowledge Base (15 Shoplite documents embedded)\n",
        "KNOWLEDGE_BASE = [\n",
        "    {\n",
        "        \"id\": \"doc1\",\n",
        "        \"title\": \"Shoplite User Registration and Account Management\",\n",
        "        \"content\": \"To create a Shoplite account, users must visit the registration page and provide a valid email address, password, and basic profile information. Email verification is required within 24 hours. Users can choose between buyer accounts (free) or seller accounts (requires business verification and tax information). Account Management Features include: Update personal information, Change passwords, Set security questions, Manage notification preferences, Deactivate accounts (requires email confirmation; may affect active orders/subscriptions). Buyer Access includes: product browsing, purchasing, order tracking, reviews. Seller Access includes: seller dashboard, inventory management, order processing, analytics. Security Measures: two-factor authentication recommended, password recovery via email and phone verification.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc2\",\n",
        "        \"title\": \"Shoplite Product Search and Filtering Features\",\n",
        "        \"content\": \"Shoplite provides a powerful search engine with keyword queries, category selection, and brand filters. Filtering Options include: price range, rating, availability, seller location, shipping speed, promotions, and eco-friendly options. Features include autocomplete suggestions, spelling correction, save searches and alerts, faceted navigation for combining multiple filters, optimization for large catalogs with real-time indexing, and a mobile responsive interface.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc3\",\n",
        "        \"title\": \"Shoplite Shopping Cart and Checkout Process\",\n",
        "        \"content\": \"Users can add multiple items from different sellers, review quantities, and apply promo codes or gift cards. The cart is preserved across sessions for logged-in users. Checkout Steps: 1) Shipping selection (standard, expedited, same-day), 2) Payment selection (credit/debit cards, digital wallets, cash-on-delivery), 3) Order confirmation. Security and Processing features include PCI-DSS compliant payment gateways, real-time stock updates, order confirmation emails with tracking, seller notifications for new orders, and an integrated returns and refunds system.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc4\",\n",
        "        \"title\": \"Shoplite Payment Methods and Security\",\n",
        "        \"content\": \"Accepted Payment Methods include credit/debit cards, PayPal, Apple Pay, Google Pay, and local payment solutions. Security Measures include SSL encryption, PCI-DSS compliance, fraud detection systems, two-factor authentication, and sensitive information encrypted both in transit and at rest. Other Features include digital wallet integration, a structured dispute and chargeback process, and seller payments processed after order confirmation.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc5\",\n",
        "        \"title\": \"Shoplite Order Tracking and Delivery\",\n",
        "        \"content\": \"Shoplite provides real-time tracking with confirmation emails and unique tracking numbers. Order Stages include: confirmed, processing, shipped, in transit, and delivered. Users can request delivery modifications (seller approval required). International shipments display customs and import duties information. The system uses optimized logistics with estimated arrival times and delay notifications. Support assistance is available for lost or delayed packages.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc6\",\n",
        "        \"title\": \"Shoplite Return and Refund Policies\",\n",
        "        \"content\": \"The return period is typically 30 days from delivery. Process: select the order and item, specify the reason, and use the prepaid label if eligible. Refunds are processed in 5‚Äì7 business days to the original payment method. Digital and personalized items may have exceptions. The system provides automated order status updates. Sellers must comply with return policies to maintain their ratings. Dispute resolution services are available for complex cases.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc7\",\n",
        "        \"title\": \"Shoplite Product Reviews and Ratings\",\n",
        "        \"content\": \"Buyers can rate products on a five-star scale and leave detailed comments. Reviews are moderated for compliance with community guidelines. Sellers can respond to reviews to address concerns. Ratings influence search ranking and product visibility. Verified purchase badges ensure review authenticity. Aggregate ratings are provided on product pages. Review analytics are available for sellers to track customer feedback trends.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc8\",\n",
        "        \"title\": \"Shoplite Seller Account Setup and Management\",\n",
        "        \"content\": \"To create a seller account, provide business documents and complete tax verification, which takes 2-3 business days. The Seller Dashboard includes inventory management, order processing, and sales analytics. Product listing is available via individual entry or bulk upload (CSV/API). Profile customization includes branding, policies, shipping options, and return policies. Sellers receive notifications for new orders, low stock alerts, and customer inquiries. Features include pricing management, promotional tools, and shipping fee configuration. Performance metrics are tracked, and third-party integrations are supported.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc9\",\n",
        "        \"title\": \"Shoplite Inventory Management for Sellers\",\n",
        "        \"content\": \"Sellers can track stock levels, set reorder thresholds, and manage availability in real-time. The system provides low-stock alerts to prevent stockouts. Bulk imports are supported for efficient inventory updates. Product variants (size, color, bundles) are fully supported. Inventory reports help identify trends and prepare for seasonal demand. Sellers can manage multiple warehouses and shipping locations from a single dashboard.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc10\",\n",
        "        \"title\": \"Shoplite Commission and Fee Structure\",\n",
        "        \"content\": \"Shoplite charges a standard 5% commission on each sale. Commission fees vary by product category. Additional fees may apply for premium listings, promotional campaigns, and special services. Transparent fee notifications are displayed in the seller dashboard. Payments are made after commission deduction on a weekly or bi-weekly schedule. Detailed transaction reports are available for accounting purposes. Pricing guidance helps sellers remain competitive.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc11\",\n",
        "        \"title\": \"Shoplite Customer Support Procedures\",\n",
        "        \"content\": \"Support is available via live chat, email, phone, and an AI chatbot, with 24/7 availability. Tickets are categorized by type: orders, payments, returns, technical issues, and account management. Each ticket receives a unique tracking ID. Backend integration provides instant access to order and payment information. A dedicated seller support channel addresses business-specific concerns. The help center includes comprehensive guides, FAQs, and video tutorials. The goal is fast, transparent, and fair resolution for all users.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc12\",\n",
        "        \"title\": \"Shoplite Mobile App Features\",\n",
        "        \"content\": \"The Shoplite mobile app supports iOS and Android devices. Users can browse products, apply filters, add items to cart, and complete purchases. Push notifications alert users to promotions and order updates. Features include barcode scanning and QR code payments for convenience. Mobile wallets, fingerprint authentication, and Face ID login enhance security. Sellers can manage their stores and process orders on-the-go. Offline caching allows users to view previously loaded content without an internet connection. The interface is intuitive, responsive, and accessible.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc13\",\n",
        "        \"title\": \"Shoplite API Documentation for Developers\",\n",
        "        \"content\": \"Shoplite provides RESTful API endpoints for product catalog access, order management, account operations, and inventory updates. Authentication uses OAuth 2.0 for secure access. Rate limiting applies to prevent abuse, with higher limits for verified partners. Detailed documentation includes request/response examples, parameter descriptions, and error code explanations. Webhooks enable real-time event notifications for orders, inventory changes, and payments. A sandbox environment is available for testing without affecting live data. The API is versioned to ensure backward-compatible updates.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc14\",\n",
        "        \"title\": \"Shoplite Security and Privacy Policies\",\n",
        "        \"content\": \"Data Protection includes TLS encryption for data in transit and AES-256 encryption for data at rest. Access is restricted to authorized personnel only. Two-factor authentication and strong password requirements protect user accounts. Shoplite complies with GDPR and CCPA regulations. Security monitoring detects suspicious activity in real-time. Clear privacy policies outline data collection, usage, and third-party sharing practices. Users are notified of policy changes and maintain control over their personal data, including the ability to download or delete their information.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc15\",\n",
        "        \"title\": \"Shoplite Promotional Codes and Discounts\",\n",
        "        \"content\": \"Sellers can create promotions including discount codes, seasonal sales, and bundle offers. Code types include percentage discounts, fixed amount discounts, and conditional discounts. Configuration options include start/end dates, usage limits, and minimum purchase requirements. Automatic verification occurs at checkout to ensure eligibility. Analytics track redemption rates, revenue impact, and customer engagement. Users receive notifications about active promotions they qualify for. Special events are highlighted on the homepage and mobile app. All promotions must comply with platform policies to ensure fairness.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Knowledge base loaded: {len(KNOWLEDGE_BASE)} documents\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "effDC2QanLDU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox97pQV-nLDW"
      },
      "source": [
        "# Cell 4: Structured Prompts (converted from YAML)\n",
        "PROMPTS = {\n",
        "    \"version\": \"1.0\",\n",
        "    \"created\": \"2025-09-26\",\n",
        "    \"author\": \"Joseph Chamoun\",\n",
        "\n",
        "    \"base_retrieval_prompt\": {\n",
        "    \"role\": \"You are a knowledgeable Shoplite customer service assistant.\",\n",
        "    \"goal\": \"Provide accurate, concise answers using only the provided Shoplite documentation.\",\n",
        "    \"context_guidelines\": [\n",
        "        \"Use only information from the provided document snippets\",\n",
        "        \"Keep answers focused and relevant\",\n",
        "        \"If information is unclear, acknowledge limitations\"\n",
        "    ],\n",
        "    \"response_format\": \"Answer: <short answer>\\nSources: <comma-separated titles>\\nConfidence: <High/Medium/Low>\"\n",
        "},\n",
        "\n",
        "\n",
        "    \"multi_doc_synthesis\": {\n",
        "        \"role\": \"You are an expert Shoplite support agent who synthesizes information from multiple documents.\",\n",
        "        \"goal\": \"Combine relevant information from multiple sources to create a comprehensive, accurate answer.\",\n",
        "        \"context_guidelines\": [\n",
        "            \"Retrieve and integrate information from all relevant documents\",\n",
        "            \"Provide step-by-step guidance if needed\",\n",
        "            \"Avoid adding information not present in the documents\",\n",
        "            \"Maintain consistency across different document sources\"\n",
        "        ],\n",
        "        \"response_format\": \"Synthesize information from multiple sources into a coherent answer.\"\n",
        "    },\n",
        "\n",
        "    \"clarification_prompt\": {\n",
        "        \"role\": \"You are a helpful Shoplite assistant that seeks clarity when needed.\",\n",
        "        \"goal\": \"Ask for clarification politely when the user query is unclear or insufficient.\",\n",
        "        \"context_guidelines\": [\n",
        "            \"Do not guess answers if the query is unclear\",\n",
        "            \"Suggest specific questions or information needed\",\n",
        "            \"Remain helpful and professional\"\n",
        "        ],\n",
        "        \"response_format\": \"Politely ask for clarification with specific guidance.\"\n",
        "    },\n",
        "\n",
        "    \"refusal_prompt\": {\n",
        "        \"role\": \"You are a responsible Shoplite assistant that only answers when relevant context is available.\",\n",
        "        \"goal\": \"Politely refuse to answer if the requested information is not found in the knowledge base.\",\n",
        "        \"context_guidelines\": [\n",
        "            \"Do not hallucinate information\",\n",
        "            \"Provide guidance on where the user may find help\",\n",
        "            \"Remain professional and helpful\"\n",
        "        ],\n",
        "        \"response_format\": \"Politely explain that the information is not available and suggest alternatives.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(PROMPTS) - 3} structured prompt configurations\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "Ox97pQV-nLDW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9zwZ3MlnLDX"
      },
      "source": [
        "# Cell 5: Build FAISS Index with Embeddings\n",
        "print(\"üîÑ Loading embedding model...\")\n",
        "EMBED_MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "embed_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
        "\n",
        "# Prepare documents for embedding\n",
        "DOCUMENT_TEXTS = [f\"{d['title']}\\n\\n{d['content']}\" for d in KNOWLEDGE_BASE]\n",
        "DOC_IDS = [d['id'] for d in KNOWLEDGE_BASE]\n",
        "\n",
        "print(\"üîÑ Creating embeddings...\")\n",
        "doc_embeddings = embed_model.encode(DOCUMENT_TEXTS, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "# Normalize for cosine similarity\n",
        "def normalize_embeddings(embs):\n",
        "    norms = np.linalg.norm(embs, axis=1, keepdims=True)\n",
        "    return embs / np.clip(norms, a_min=1e-10, a_max=None)\n",
        "\n",
        "doc_embeddings = normalize_embeddings(doc_embeddings)\n",
        "\n",
        "# Build FAISS index\n",
        "dimension = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "print(f\"‚úÖ FAISS index built: {index.ntotal} vectors (dim={dimension})\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "K9zwZ3MlnLDX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoLI92xvnLDX"
      },
      "source": [
        "# Cell 6: Retrieval Function\n",
        "def retrieve_docs(query: str, top_k: int = 3):\n",
        "    \"\"\"Retrieve most relevant documents for a query.\"\"\"\n",
        "    q_emb = embed_model.encode([query], convert_to_numpy=True)\n",
        "    q_emb = normalize_embeddings(q_emb)\n",
        "\n",
        "    scores, indices = index.search(q_emb, top_k)\n",
        "\n",
        "    results = []\n",
        "    for score, idx in zip(scores[0], indices[0]):\n",
        "        if 0 <= idx < len(KNOWLEDGE_BASE):\n",
        "            doc = KNOWLEDGE_BASE[idx]\n",
        "            results.append({\n",
        "                'id': doc['id'],\n",
        "                'title': doc['title'],\n",
        "                'content': doc['content'],\n",
        "                'score': float(score)\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Quick test\n",
        "test_results = retrieve_docs(\"How do I create a seller account?\", top_k=3)\n",
        "print(f\"‚úÖ Retrieval test passed: Found {len(test_results)} relevant docs\")\n",
        "print(f\"   Top match: {test_results[0]['title']} (score: {test_results[0]['score']:.3f})\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "yoLI92xvnLDX"
    },
    {
      "cell_type": "code",
      "source": [
        "# huggingface_login.py\n",
        "# HuggingFace Authentication\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "print(\"üîê HuggingFace Authentication\")\n",
        "print(\"=\" * 60)\n",
        "print(\"To access Llama models, you need a HuggingFace token.\")\n",
        "print(\"Get your token from: https://huggingface.co/settings/tokens\")\n",
        "print(\"Make sure you've accepted the Llama model license at:\")\n",
        "print(\"  ‚Ä¢ https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\")\n",
        "print(\"  ‚Ä¢ https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "hf_token = input(\"\\nEnter your HuggingFace token: \").strip()\n",
        "\n",
        "if not hf_token:\n",
        "    print(\"\\n‚ö†Ô∏è  No token provided. Model loading will fail.\")\n",
        "    print(\"   System will fall back to extractive-only responses.\")\n",
        "else:\n",
        "    try:\n",
        "        login(token=hf_token)\n",
        "        print(\"\\n‚úÖ Successfully authenticated with HuggingFace!\")\n",
        "        print(\"   You can now access gated models like Llama.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Authentication failed: {e}\")\n",
        "        print(\"   Please check your token and try again.\")\n",
        "        print(\"   System will fall back to extractive-only responses.\")\n"
      ],
      "metadata": {
        "id": "1gQxF-S-nH0W"
      },
      "id": "1gQxF-S-nH0W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfyCXmAPnLDY"
      },
      "source": [
        "# Cell 7: Load LLM with Quantization\n",
        "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "FALLBACK_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"  # Smaller fallback\n",
        "\n",
        "print(f\"üîÑ Loading model: {MODEL_NAME}\")\n",
        "print(f\"üí° Fallback available: {FALLBACK_MODEL}\")\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(f\"{'üî•' if use_cuda else '‚ö†Ô∏è'} CUDA available: {use_cuda}\")\n",
        "\n",
        "model = None\n",
        "tokenizer = None\n",
        "loaded_model_name = None\n",
        "\n",
        "def try_load_model(model_name: str):\n",
        "    \"\"\"Attempt to load model with 8-bit quantization.\"\"\"\n",
        "    try:\n",
        "        print(f\"  Attempting: {model_name}\")\n",
        "\n",
        "        tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "        # Configure 8-bit quantization\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_8bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        mdl = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            device_map=\"auto\" if use_cuda else None,\n",
        "            quantization_config=bnb_config if use_cuda else None,\n",
        "            torch_dtype=torch.float16,\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "\n",
        "        mdl.eval()\n",
        "        print(f\"  ‚úÖ Success!\")\n",
        "        return tok, mdl, model_name\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Failed: {str(e)[:100]}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Try primary model\n",
        "tokenizer, model, loaded_model_name = try_load_model(MODEL_NAME)\n",
        "\n",
        "# Try fallback if primary fails\n",
        "if model is None:\n",
        "    print(f\"\\nüîÑ Trying fallback model...\")\n",
        "    tokenizer, model, loaded_model_name = try_load_model(FALLBACK_MODEL)\n",
        "\n",
        "# Final status\n",
        "if model is not None:\n",
        "    print(f\"\\n‚úÖ MODEL LOADED: {loaded_model_name}\")\n",
        "    print(f\"   Memory: ~{torch.cuda.memory_allocated() / 1e9:.1f} GB\" if use_cuda else \"   Running on CPU\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No model loaded - will use extractive responses from retrieved docs\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "tfyCXmAPnLDY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyO4x8ZQnLDY"
      },
      "source": [
        "# Cell 8: Complete Generation Function with Natural Answers\n",
        "SIMILARITY_THRESHOLD = 0.20\n",
        "MAX_NEW_TOKENS = 400  # allow longer answers\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "def build_prompt_from_retrieval(query: str, retrieved_docs: List[Dict[str, Any]]):\n",
        "    \"\"\"Build prompt with strict single-answer format.\"\"\"\n",
        "    docs_text = \"\"\n",
        "    for doc in retrieved_docs[:2]:  # only top 2 docs\n",
        "        content = doc['content'][:600] if len(doc['content']) > 600 else doc['content']\n",
        "        docs_text += f\"\\n{content}\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a knowledgeable Shoplite customer service assistant.\n",
        "\n",
        "    Knowledge:\n",
        "    {docs_text}\n",
        "\n",
        "    User Question: {query}\n",
        "\n",
        "    Instructions:\n",
        "    - Provide **one single clear answer** in 2‚Äì4 sentences\n",
        "    - Do not list multiple separate answers\n",
        "    - Do not include greetings, notes, or explanations\n",
        "    - Format must be exactly:\n",
        "\n",
        "    Answer: <your concise answer>\n",
        "    Sources: <comma-separated document titles>\n",
        "    Confidence: <High/Medium/Low>\n",
        "    \"\"\"\n",
        "\n",
        "    return prompt.strip()\n",
        "\n",
        "\n",
        "\n",
        "def generate_response(query: str, top_k: int = 3, debug: bool = False):\n",
        "    \"\"\"Generate response using RAG pipeline with natural language answers.\"\"\"\n",
        "    retrieved = retrieve_docs(query, top_k=top_k)\n",
        "    if not retrieved:\n",
        "        return {\n",
        "            \"answer\": \"I couldn‚Äôt find information about that in the Shoplite knowledge base. Could you rephrase or ask about accounts, orders, payments, returns, or support?\",\n",
        "            \"sources\": [],\n",
        "            \"confidence\": \"Low\"\n",
        "        }\n",
        "\n",
        "    top_score = max(d['score'] for d in retrieved)\n",
        "    if top_score < SIMILARITY_THRESHOLD:\n",
        "        return {\n",
        "            \"answer\": \"I don‚Äôt have specific information about that, but I can help with Shoplite accounts, orders, payments, returns, and support.\",\n",
        "            \"sources\": [],\n",
        "            \"confidence\": \"Low\"\n",
        "        }\n",
        "\n",
        "    prompt = build_prompt_from_retrieval(query, retrieved)\n",
        "\n",
        "    if model is None:\n",
        "        # Fallback: extractive\n",
        "        return {\n",
        "            \"answer\": retrieved[0]['content'],\n",
        "            \"sources\": [d['title'] for d in retrieved[:2]],\n",
        "            \"confidence\": \"Medium\"\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        inputs = tokenizer(prompt, return_tensors='pt', truncation=True, max_length=1800)\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=MAX_NEW_TOKENS,\n",
        "            temperature=TEMPERATURE,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        gen_ids = outputs[0][inputs['input_ids'].shape[1]:]\n",
        "        answer = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "        if len(answer) > 1500:  # safeguard\n",
        "            cut = answer[:1500]\n",
        "            stop = max(cut.rfind('.'), cut.rfind('!'), cut.rfind('?'))\n",
        "            answer = cut[:stop+1] if stop != -1 else cut\n",
        "\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"sources\": [d['title'] for d in retrieved[:2]],  # ‚úÖ keep sources\n",
        "            \"confidence\": \"High\" if top_score >= 0.5 else \"Medium\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        if debug:\n",
        "            print(f\"[DEBUG] Generation error: {e}\")\n",
        "        return {\n",
        "            \"answer\": retrieved[0]['content'],\n",
        "            \"sources\": [d['title'] for d in retrieved[:2]],\n",
        "            \"confidence\": \"Medium\"\n",
        "        }\n",
        "\n",
        "print(\"‚úÖ Generation pipeline updated: longer answers + no doc references (sources preserved)\")\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "pyO4x8ZQnLDY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flask_api_setup"
      },
      "source": [
        "# Cell 9: Flask API Setup\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    \"\"\"Health check endpoint.\"\"\"\n",
        "    return jsonify({\n",
        "        \"status\": \"running\",\n",
        "        \"model_loaded\": model is not None,\n",
        "        \"model_name\": loaded_model_name if model else \"None\",\n",
        "        \"num_docs\": len(KNOWLEDGE_BASE),\n",
        "        \"embedding_model\": EMBED_MODEL_NAME\n",
        "    })\n",
        "\n",
        "@app.route('/ping', methods=['POST'])\n",
        "def ping():\n",
        "    \"\"\"Direct LLM interaction without RAG.\"\"\"\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        query = data.get('query', '')\n",
        "\n",
        "        if not query:\n",
        "            return jsonify({\"error\": \"No query provided\"}), 400\n",
        "\n",
        "        if model is None:\n",
        "            return jsonify({\"error\": \"Model not loaded\"}), 503\n",
        "\n",
        "        inputs = tokenizer(query, return_tensors='pt', truncation=True, max_length=512)\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=100,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "        return jsonify({\n",
        "            \"response\": response.strip(),\n",
        "            \"query\": query\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    \"\"\"RAG-powered chat endpoint.\"\"\"\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        query = data.get('query', '')\n",
        "        top_k = data.get('top_k', 3)\n",
        "\n",
        "        if not query:\n",
        "            return jsonify({\"error\": \"No query provided\"}), 400\n",
        "\n",
        "        result = generate_response(query, top_k=top_k)\n",
        "\n",
        "        return jsonify(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "print(\"‚úÖ Flask API configured with /health, /ping, /chat endpoints\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "flask_api_setup"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngrok_tunnel_setup"
      },
      "source": [
        "# Cell 10: ngrok Tunnel Setup\n",
        "print(\"üîê ngrok Setup\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# SECURITY: Accept token at runtime\n",
        "ngrok_token = input(\"Enter your ngrok auth token: \").strip()\n",
        "\n",
        "if not ngrok_token:\n",
        "    print(\"‚ùå No token provided. Cannot create tunnel.\")\n",
        "else:\n",
        "    try:\n",
        "        # Set ngrok token\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "        # Start Flask in background thread\n",
        "        def run_flask():\n",
        "            app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "        flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
        "        flask_thread.start()\n",
        "\n",
        "        # Wait for Flask to start\n",
        "        time.sleep(3)\n",
        "\n",
        "        # Create ngrok tunnel\n",
        "        public_url = ngrok.connect(5000, bind_tls=True)\n",
        "\n",
        "        print(\"\\n‚úÖ TUNNEL ACTIVE\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"üåê Public URL: {public_url}\")\n",
        "        print(\"=\" * 50)\n",
        "        print(\"\\nAPI Endpoints:\")\n",
        "        print(f\"  ‚Ä¢ Health: {public_url}/health\")\n",
        "        print(f\"  ‚Ä¢ Chat:   {public_url}/chat\")\n",
        "        print(f\"  ‚Ä¢ Ping:   {public_url}/ping\")\n",
        "        print(\"\\nüí° Copy the URL above to use in chat-interface.py\")\n",
        "        print(\"‚ö†Ô∏è  Keep this cell running - do not stop execution!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Tunnel creation failed: {e}\")\n",
        "        print(\"Please check your ngrok token and try again.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ngrok_tunnel_setup"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "system_validation"
      },
      "source": [
        "# Cell 11: System Validation and Testing\n",
        "import random\n",
        "\n",
        "print(\"üß™ Running System Tests...\\n\")\n",
        "\n",
        "# Predefined random questions for testing variety\n",
        "random_questions = [\n",
        "    \"How do I reset my password?\",\n",
        "    \"Can I track my order on Shoplite?\",\n",
        "    \"What are the shipping options available?\",\n",
        "    \"Does Shoplite support refunds?\",\n",
        "    \"How do I update my account information?\",\n",
        "    \"What is Shoplite‚Äôs return policy?\",\n",
        "    \"Does Shoplite accept Apple Pay?\",\n",
        "    \"How can I contact Shoplite customer support?\",\n",
        "    \"How do I become a Shoplite seller?\",\n",
        "    \"What are Shoplite‚Äôs security measures for payments?\"\n",
        "]\n",
        "\n",
        "# ---- Fixed Core Tests ----\n",
        "\n",
        "# Test 1: Conversational Query\n",
        "print(\"Test 1: Conversational Handling\")\n",
        "greeting_response = generate_response(\"Hi\")\n",
        "print(f\"‚úÖ Greeting: '{greeting_response['answer']}...'\")\n",
        "assert \"Shoplite\" in greeting_response['answer'], \"Should mention Shoplite\"\n",
        "print(\"   ‚úì Conversational query handled correctly\")\n",
        "\n",
        "# Test 2: How are you\n",
        "print(\"\\nTest 2: How Are You\")\n",
        "how_response = generate_response(\"How are you?\")\n",
        "print(f\"‚úÖ Response: '{how_response['answer']}...'\")\n",
        "assert len(how_response['answer']) < 150, \"Should be brief\"\n",
        "print(\"   ‚úì Brief conversational response\")\n",
        "\n",
        "# ---- Randomized Tests ----\n",
        "print(\"\\nüåÄ Running 5 Randomized Tests\")\n",
        "sample_qs = random.sample(random_questions, 5)\n",
        "\n",
        "for i, q in enumerate(sample_qs, start=1):\n",
        "    print(f\"\\nRandom Test {i}: {q}\")\n",
        "    response = generate_response(q)\n",
        "    print(f\"‚úÖ Response: '{response['answer']}...'\")\n",
        "    if response['sources']:\n",
        "        print(f\"   Sources: {', '.join(response['sources'][:2])}\")\n",
        "    print(f\"   Confidence: {response['confidence']}\")\n",
        "    assert len(response['answer']) > 30, \"Answer should not be too short\"\n",
        "\n",
        "# ---- Out of Scope ----\n",
        "print(\"\\nTest: Out-of-Scope Query\")\n",
        "oos_q = \"What's the weather like today?\"\n",
        "response = generate_response(oos_q)\n",
        "print(f\"‚úÖ Handled: '{response['answer']}...'\")\n",
        "print(f\"   Confidence: {response['confidence']}\")\n",
        "if response['confidence'] == 'Low':\n",
        "    print(\"   ‚úì Correctly identified as out-of-scope\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ ALL TESTS COMPLETED - System Functional!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüìã System Summary:\")\n",
        "print(f\"  ‚Ä¢ Knowledge Base: {len(KNOWLEDGE_BASE)} documents\")\n",
        "print(f\"  ‚Ä¢ Embedding Model: {EMBED_MODEL_NAME}\")\n",
        "print(f\"  ‚Ä¢ LLM: {loaded_model_name if model else 'Extractive Mode'}\")\n",
        "print(f\"  ‚Ä¢ FAISS Index: {index.ntotal} vectors\")\n",
        "print(f\"  ‚Ä¢ Threshold: {SIMILARITY_THRESHOLD}\")\n",
        "print(f\"  ‚Ä¢ Conversational: Enabled\")\n",
        "if model is None:\n",
        "    print(\"\\n‚ö†Ô∏è  NOTE: Running in extractive mode without LLM.\")\n",
        "    print(\"   Provide HuggingFace token for full generative capabilities.\")\n",
        "print(\"\\nüöÄ Ready to accept chat requests!\")\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "system_validation"
    }
  ]
}
